\documentclass[010-intro.tex]{subfiles}

\begin{document}

\subsection{Where the term came from}

    Statistics and computer science has always been associated with ``data science''.
    In 1962, John Tukey describes data analysis as ``intrinsically an empirical science''
    and points to electronic computers as being vital to data analysis
    \cite{tukeyFutureDataAnalysis1962, pressVeryShortHistory}.
    This scientific approach to data analysis,
    with hypothesis driven exploration, was later called ``Exploratory Data Analysis'', and in 1977,
    Tukey calls for exploratory data analysis to be used along with confirmatory data analysis by understanding
    the data first before calculating any confirmatory statistic
    \cite{tukeyExploratoryDataAnalysis1977}.

    % Somewhere in this timeline there was an article about statistics and putting things off to other domains

    By 1974, Peter Naur \cite{pressVeryShortHistory} defines ``data science'' as:

    \begin{displayquote}
        The science of dealing with data, once they have been established,
        while the relation of the data to what they represent is delegated to other fields and sciences.
    \end{displayquote}

    While data science did not take on mainstream adoption as a term for the type of skills needed to work with data,
    statisticians realized that many of the kinds of insights they have come from using computational tools. % TODO [citation_needed].
    In 1997, C. F. Jeff Wu at the University of Michigan called for a rebranding of
    ``statistics'' and ``statisticians'' in favor of
    ``data science'' and ``data scientists'', respectively,
    since many other ``good'' names were already taken
    (e.g., computer science, information science, material science, cognitive science).

    In 1998, John Chambers was awarded the ACM Software System Award for the S system for graphics and data analysis.
    By 2001, the field of ``data science'' was born with William Cleveland's plan to expand the technical areas of statistics.
    Cleveland proposed six (6) technical areas and how university resources should be allocated \cite{clevelandDataScienceAction2001}:

    \begin{enumerate}
        \item Multidisciplinary Investigations (25\%):
            data analysis collaborations in a collection of subject matter areas
        \item Models and methods for Data (20\%):
            statistical models; methods of model building; methods of estimation and distribution based on probabilistic inference.
        \item Computing with Data (15\%):
            hardware systems; software systems; computational algorithms
        \item Pedagogy (15\%):
            curriculum planning and approaches to teaching for
            elementary school, secondary school, college, graduate school, continuing education, and corporate training
        \item Tool Evaluation (5\%):
            surveys of tools in use in practice, surveys of perceived needs for new tools, and studies of the processes for developing new tools
        \item Theory (20\%):
            foundations of data science;
            general approaches to models and methods, computing with data, teaching, and tool evaluation;
            mathematical investigations of models and methods, computing with data, teaching, and evaluation
    \end{enumerate}

    Since universities have been traditional institutions for innovation,
    along with government research labs,
    and corporate research organizations,
    they can shape what is taught to new graduates to progress data science
    \cite{clevelandDataScienceAction2001}.
    In 2002 the ``Data Science Journal'' was launched,
    and by 2003, the ``Journal of Data Science'' was launched
    to present and share ideas.

    Hal Varian, Google's Chief Economist, mentions in McKinsey Quarterly in 2009,
    computer engineers was the sexy job in the 1990s,
    statisticians would be the sexy job in the next 10 years.
    Varian alludes to
    the need to visualize and learn from the ubiquitous amount of data and
    many of these skills will need to be transferred to managers who need to understand the data themselves.
    As data science becomes a more common term,
    in 2010 Hilary Mason and Chris Wiggins write ``A Taxonomy of Data Science''
    \cite{masonTaxonomyDataScience2010}
    and
    Drew Conway creates ``The Data Science Venn Diagram''
    that aims to clarify what is data science and what skills are needed to be a competent data scientist
    \cite{conwayDataScienceVenn}.
    Mason and Wiggins's Snice taxonomy (aka OSEMN) states that a data scientist, % TODO define
    in rough chronological order,
    obtains, scrubs, explores, models, and i(n)terprets data.
    In 2012 Tom Davenport and D.J. Patil publish ``Data Scientist: The Sexiest Job of the 21st Century'' in the Harvard Business Review, which talk about the types of insights data science can bring,
    while also describing the multitudes of skills a data scientist needs to incorporate into analysis,
    mainly around working with unstructured data to create and present an analysis
    \cite{davenportDataScientistSexiest2012}.
    Davenport and Patil also talk about the high cost and scarcity of data scientists,
    how businesses must balance the need to stay competitive with the nonstop flow of data,
    and waiting for the next wave of talent that is more accessible
    due to a data scientist's rarefied skills become taught in classes.
    Patil is later named the First U.S. Chief Data Scientist in 2015.
    Meanwhile, data science has started to impact the growth of open source in the academic, scientific, and research domains % citation_needed
    Arfon Smith, Kyle Niemeyer, Dan Katz, Kevin Moerman, and Karthik Ram start
    the Journal of Open Source Software in 2016, and by 2018,
    The National Institute of Health (NIH) released its first Strategic Plan for Data Science
    that provides a road map for the biomedical data science ecosystem.

    While ``data science'' may be a relatively new term,
    it may evolve just like the evolution of ``statistics'', ``machine learning'', and ``artificial intelligence''
    in mainstream terminology.
    But, the core skills of obtaining, cleaning, analyzing, and communicating data insights will remain the same.

\end{document}
